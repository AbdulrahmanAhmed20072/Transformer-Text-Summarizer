{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ArVLRskqvfJF",
        "PDmSrq1Xv-zH",
        "XCGjt2f0q5Jc",
        "SUlP5YqYt97C",
        "6VNjDpfw-wxD",
        "PA6qPHI01MzV",
        "g_Zlfy6xrgew",
        "sPom3AHZwmFi",
        "XZc-xsO7PITJ"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import the Dataset\n"
      ],
      "metadata": {
        "id": "ArVLRskqvfJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q dlai-grader==1.20.0 tensorflow==2.18.0 numpy==1.26.4 pandas==2.2.2"
      ],
      "metadata": {
        "id": "aGfMext9-b19"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from utils_transformer import get_train_test_data, preprocess\n",
        "\n",
        "tf.keras.utils.set_random_seed(10)"
      ],
      "metadata": {
        "id": "R5T6KMkmcYRj"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = get_train_test_data(\".\")"
      ],
      "metadata": {
        "id": "2qM8RcSZL4qy"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocess the data"
      ],
      "metadata": {
        "id": "OemuUGMAvlXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_summary, example_dialogue = train_data.iloc[10]\n",
        "\n",
        "print(f\"dialogue:\\n{example_dialogue}\\n\")\n",
        "print(f\"summary:\\n{example_summary}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj4TTvmrODfi",
        "outputId": "21090715-84f7-480d-e3f2-5e7e6f55ad6d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dialogue:\n",
            "Lucas: Hey! How was your day?\r\n",
            "Demi: Hey there! \r\n",
            "Demi: It was pretty fine, actually, thank you!\r\n",
            "Demi: I just got promoted! :D\r\n",
            "Lucas: Whoa! Great news!\r\n",
            "Lucas: Congratulations!\r\n",
            "Lucas: Such a success has to be celebrated.\r\n",
            "Demi: I agree! :D\r\n",
            "Demi: Tonight at Death & Co.?\r\n",
            "Lucas: Sure!\r\n",
            "Lucas: See you there at 10pm?\r\n",
            "Demi: Yeah! See you there! :D\n",
            "\n",
            "summary:\n",
            "Demi got promoted. She will celebrate that with Lucas at Death & Co at 10 pm.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary, document = preprocess(train_data)\n",
        "summary_test, document_test = preprocess(test_data)"
      ],
      "metadata": {
        "id": "E2vjPAfWOH1S"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters = '!\"#$%&()*+,-./:;<=>?@\\\\^_`{|}~\\t\\n'\n",
        "oov_token = '[UNK]'\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    filters = filters,\n",
        "    lower = False,\n",
        "    oov_token = oov_token\n",
        "    )\n",
        "\n",
        "documents_and_summary = pd.concat([document, summary], ignore_index = True)\n",
        "\n",
        "# create the vocabulary\n",
        "tokenizer.fit_on_texts(documents_and_summary)\n",
        "\n",
        "# convert words to vectors\n",
        "inputs = tokenizer.texts_to_sequences(document)\n",
        "targets = tokenizer.texts_to_sequences(summary)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(f'Size of vocabulary: {vocab_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7SJYTFgQdqB",
        "outputId": "3e8a0dc9-8521-4db3-b508-7e75eb45c1a3"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 34250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_maxlen = 150\n",
        "decoder_maxlen = 50\n",
        "\n",
        "# apply padding\n",
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences = inputs,\n",
        "    maxlen = encoder_maxlen,\n",
        "    padding = 'post',\n",
        "    truncating = 'post')\n",
        "\n",
        "targets = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences = targets,\n",
        "    maxlen = decoder_maxlen,\n",
        "    padding = 'post',\n",
        "    truncating = 'post')"
      ],
      "metadata": {
        "id": "NcmeNa0HUdKU"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert vectors to float32\n",
        "inputs = tf.cast(inputs, tf.float32)\n",
        "targets = tf.cast(targets, tf.float32)"
      ],
      "metadata": {
        "id": "kGo9opQjUiEZ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 10000\n",
        "batch_size = 64\n",
        "\n",
        "# create the dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    tensors = (inputs, targets)).shuffle(BUFFER_SIZE).batch(batch_size)"
      ],
      "metadata": {
        "id": "Le4wOnR4WhSo"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataset.take(1):\n",
        "    print(f\"first input sample shape: {i[0].shape}\")\n",
        "    print(f\"first target sample shape: {i[1].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLLKmoDSXmAH",
        "outputId": "9cc37774-6783-4cf3-c3c9-061a4016fc26"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first input sample shape: (64, 150)\n",
            "first target sample shape: (64, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Positional Encoding"
      ],
      "metadata": {
        "id": "PDmSrq1Xv-zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(positions, d_model):\n",
        "\n",
        "    position = np.arange(positions)[:, np.newaxis]\n",
        "    k = np.arange(d_model)[np.newaxis, :]\n",
        "    i = k // 2\n",
        "\n",
        "    # initialize a matrix angle_rads of all the angles\n",
        "    angle_rates = 1 / np.power(10000, (2 * i) / np.float32(d_model))\n",
        "    angle_rads = position * angle_rates\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "8qMi6xqQZrZc"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Masking\n"
      ],
      "metadata": {
        "id": "baZ9PqpFv2MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(decoder_token_ids):\n",
        "\n",
        "    \"Creates a matrix mask for the padding cells\"\n",
        "\n",
        "    seq = 1 - tf.cast(tf.equal(decoder_token_ids, 0), decoder_token_ids.dtype)\n",
        "\n",
        "    return seq[:, tf.newaxis, :]"
      ],
      "metadata": {
        "id": "a-IfDBs3t45M"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_padding_mask(tf.constant([[1,2,0],\n",
        "                                 [3,0,0]],dtype = tf.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W398tRdNwjAc",
        "outputId": "bf5ccb14-8a92-4a85-ca6a-01ba01ab7096"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1, 3), dtype=float32, numpy=\n",
              "array([[[1., 1., 0.]],\n",
              "\n",
              "       [[1., 0., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(sequence_length):\n",
        "\n",
        "    \"Returns a lower triangular matrix filled with ones\"\n",
        "\n",
        "    ones = tf.ones((1, sequence_length, sequence_length))\n",
        "\n",
        "    # num_lower = -1 means fill under diagonal with ones,\n",
        "    # num_upper = 0 means let upper the diagonal with zeros\n",
        "    return tf.linalg.band_part(ones, num_lower = -1, num_upper = 0)"
      ],
      "metadata": {
        "id": "S6DKN4gqwxau"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1,2,0], [3,0,0], [1,2,1]], dtype = tf.float32)\n",
        "\n",
        "create_look_ahead_mask(a.shape[-2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_gdeP0-z0NJ",
        "outputId": "9190c09f-01e2-4583-9c63-921cc23f36ef"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\n",
              "array([[[1., 0., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 1.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#self-attention"
      ],
      "metadata": {
        "id": "XCGjt2f0q5Jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "\n",
        "    align = tf.matmul(q, k, transpose_b = True)\n",
        "\n",
        "    dk = tf.cast(k.shape[-1], align.dtype)\n",
        "    scaled_align = align / tf.math.sqrt(dk)\n",
        "\n",
        "    # musk should be applied before softmax\n",
        "    if mask is not None:\n",
        "        scaled_align += (1.0 - mask) * -1e9\n",
        "\n",
        "    weights = tf.nn.softmax(scaled_align)\n",
        "\n",
        "    context = tf.matmul(weights, v)\n",
        "\n",
        "    return context, weights"
      ],
      "metadata": {
        "id": "I41x3D1-0HWP"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = tf.constant([[1,2,0], [3,0,0], [1,2,1]], dtype = tf.float32)\n",
        "\n",
        "k = tf.constant([[1,2,0], [3,0,0], [1,2,1]], dtype = tf.float32)\n",
        "\n",
        "v = tf.constant([[1,2,0], [3,0,0], [1,2,1]], dtype = tf.float32)\n",
        "\n",
        "scaled_dot_product_attention(q, k, v, None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_0POlTwXjt6",
        "outputId": "02ce58d1-0d6f-4f2b-cccf-4615856aab08"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              " array([[1.2722516 , 1.7277484 , 0.4319371 ],\n",
              "        [2.8821719 , 0.11782812, 0.02945703],\n",
              "        [1.203556  , 1.7964439 , 0.57527304]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              " array([[0.4319371 , 0.1361258 , 0.4319371 ],\n",
              "        [0.02945703, 0.9410859 , 0.02945703],\n",
              "        [0.32294896, 0.10177799, 0.57527304]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the function\n",
        "q = np.array([[1, 1, 0, 1],\n",
        "              [0, 1, 1, 1],\n",
        "              [1, 0, 1, 1]]).astype(np.float32)\n",
        "\n",
        "k = np.array([[1, 1, 0, 1],\n",
        "              [1, 0, 1, 1],\n",
        "              [1, 1, 1, 0],\n",
        "              [0, 0, 0, 1],\n",
        "              [0, 1, 0, 1]]).astype(np.float32)\n",
        "\n",
        "v = np.array([[0, 0],\n",
        "              [1, 0],\n",
        "              [1, 0],\n",
        "              [1, 1],\n",
        "              [1, 1]]).astype(np.float32)\n",
        "\n",
        "mask = np.array([[[0, 1, 0, 1, 1],\n",
        "                  [1, 0, 0, 1, 1],\n",
        "                  [1, 1, 0, 1, 1]]])\n",
        "\n",
        "ou, atw = scaled_dot_product_attention(q, k, v, mask)\n",
        "ou = np.around(ou, decimals=2)\n",
        "atw = np.around(atw, decimals=2)\n",
        "\n",
        "print(f\"Output:\\n {ou}\")\n",
        "print(f\"\\nAttention weigths:\\n {atw}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff-Dpx2cXnxq",
        "outputId": "30a22bc6-5003-462a-b568-e503889a2c00"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            " [[[1.   0.62]\n",
            "  [0.62 0.62]\n",
            "  [0.74 0.31]]]\n",
            "\n",
            "Attention weigths:\n",
            " [[[0.   0.38 0.   0.23 0.38]\n",
            "  [0.38 0.   0.   0.23 0.38]\n",
            "  [0.26 0.43 0.   0.16 0.16]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoder"
      ],
      "metadata": {
        "id": "SUlP5YqYt97C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def FullyConnected(embedding_dim, fully_connected_dim):\n",
        "\n",
        "    ffnn = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(fully_connected_dim, activation='relu'),\n",
        "        tf.keras.layers.Dense(embedding_dim)])\n",
        "\n",
        "    return ffnn"
      ],
      "metadata": {
        "id": "Miqk9W_gbSMC"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, num_heads, embedding_dim,\n",
        "                 fully_connected_dim, dropout_rate = 0.1,\n",
        "                 layernorm_eps = 1e-6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(\n",
        "                num_heads = num_heads,\n",
        "                key_dim = embedding_dim,\n",
        "                dropout = dropout_rate,\n",
        "            )\n",
        "\n",
        "        self.ffn = FullyConnected(\n",
        "                embedding_dim,\n",
        "                fully_connected_dim\n",
        "            )\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = layernorm_eps)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = layernorm_eps)\n",
        "\n",
        "        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def __call__(self, x, is_training, mask):\n",
        "\n",
        "        # since we are in encoder, use the same i/p for qkv\n",
        "        self_mha_output = self.mha(\n",
        "            query = x, key = x, value = x, attention_mask = mask)\n",
        "\n",
        "        # residual connection and normalization\n",
        "        skip_x_attention = self.layernorm1(x + self_mha_output)\n",
        "\n",
        "        # feed forward nn\n",
        "        ffn_output = self.ffn(skip_x_attention)\n",
        "\n",
        "        # apply dropout just for training\n",
        "        ffn_output = self.dropout_ffn(ffn_output, training = is_training)\n",
        "\n",
        "        # another residual connection and normalization\n",
        "        encoder_layer_out = self.layernorm2(skip_x_attention + ffn_output)\n",
        "\n",
        "        return encoder_layer_out"
      ],
      "metadata": {
        "id": "IEqJKUAP6o1i"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.random.uniform((1,3,5))\n",
        "\n",
        "E = EncoderLayer(num_heads = 1,\n",
        "                 embedding_dim = 5,\n",
        "                 fully_connected_dim= 120)\n",
        "\n",
        "E(x = x, is_training = True, mask = None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFg4WIqRZY3C",
        "outputId": "b8dba347-014d-4952-bfe6-ee6c9490695f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3, 5), dtype=float32, numpy=\n",
              "array([[[ 0.7081839 ,  0.41457322, -1.5866754 ,  1.1543071 ,\n",
              "         -0.6903888 ],\n",
              "        [ 1.313329  , -0.37334985, -1.6875824 ,  0.30907148,\n",
              "          0.43853182],\n",
              "        [ 1.1260601 , -0.1944412 , -0.70851934,  1.1468799 ,\n",
              "         -1.3699793 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "\n",
        "    \"\"\"\n",
        "      the full encoder starts with passing the i/p to embedding layer\n",
        "      and ends with a contextual representation for the sequance\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_layers, vocab_size,\n",
        "                 embedding_dim, maximum_position_encoding,\n",
        "                 num_heads, fully_connected_dim,\n",
        "                 dropout_rate=0.1, layernorm_eps=1e-6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(\n",
        "            input_dim = vocab_size,\n",
        "            output_dim = embedding_dim,\n",
        "            mask_zero = True # ignaoring 0 in calcualtions\n",
        "        )\n",
        "\n",
        "        self.pos_encoding = positional_encoding(\n",
        "            maximum_position_encoding,\n",
        "            embedding_dim\n",
        "        )\n",
        "\n",
        "        # repreating encoder layer for certain num of layers\n",
        "        self.enc_layer = [\n",
        "            EncoderLayer(num_heads,\n",
        "                         embedding_dim,\n",
        "                         fully_connected_dim,\n",
        "                         dropout_rate,\n",
        "                         layernorm_eps)\n",
        "\n",
        "            for _ in range(num_layers)\n",
        "            ]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, is_training, mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # this scaling process helps maintain a good balance between\n",
        "        # the learned embeddings and the fixed positional encodings\n",
        "        # because the embedding is a slightly smaller than the positional encoding values\n",
        "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
        "\n",
        "        # add positional encoding values\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=is_training)\n",
        "\n",
        "        # iterate over encoder layer for n times\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layer[i](x, is_training, mask)\n",
        "\n",
        "        return x # (batch_size, input_seq_len, embedding_dim)"
      ],
      "metadata": {
        "id": "Jmt0Ul6-_miu"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.random.uniform((1,2))\n",
        "\n",
        "E = Encoder(num_layers=2, vocab_size=vocab_size,\n",
        "                 embedding_dim=10,maximum_position_encoding=100,\n",
        "                 num_heads=8, fully_connected_dim=150,\n",
        "                 dropout_rate=0.1, layernorm_eps=1e-6)\n",
        "\n",
        "encoder_out = E(x, is_training = True, mask= None)\n",
        "encoder_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G9tNl0UoDflS",
        "outputId": "58072c4d-9344-4a48-dff5-a845a7f12733"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'encoder_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 10), dtype=float32, numpy=\n",
              "array([[[-0.30631414,  1.0099329 , -1.2527146 ,  0.72792435,\n",
              "         -0.4140447 ,  0.3989549 , -1.2532282 ,  0.41933027,\n",
              "         -1.162495  ,  1.8326545 ],\n",
              "        [-0.20135403, -0.26914924, -0.4888366 ,  0.5466636 ,\n",
              "         -0.6971479 ,  0.9217518 , -1.1409347 ,  0.2441242 ,\n",
              "         -1.1987865 ,  2.2836695 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder"
      ],
      "metadata": {
        "id": "PA6qPHI01MzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n",
        "                 dropout_rate = 0.1, layernorm_eps = 1e-6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.mha1 = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads = num_heads,\n",
        "            key_dim = embedding_dim,\n",
        "            dropout = dropout_rate\n",
        "        )\n",
        "\n",
        "        self.mha2 = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads = num_heads,\n",
        "            key_dim = embedding_dim,\n",
        "            dropout = dropout_rate\n",
        "        )\n",
        "\n",
        "        self.ffn = FullyConnected(\n",
        "            embedding_dim,\n",
        "            fully_connected_dim\n",
        "        )\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(\n",
        "            epsilon = layernorm_eps\n",
        "        )\n",
        "\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(\n",
        "            epsilon = layernorm_eps\n",
        "        )\n",
        "\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(\n",
        "            epsilon = layernorm_eps\n",
        "        )\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(\n",
        "            rate = dropout_rate\n",
        "        )\n",
        "\n",
        "    def call(self, x, encoder_output, is_training,\n",
        "             look_ahead_mask, padding_mask):\n",
        "\n",
        "        # masked multi head attention layer\n",
        "        multi_attn_out_1, masked_attention_weights = self.mha1(\n",
        "            query = x,\n",
        "            key = x,\n",
        "            value = x,\n",
        "            attention_mask = look_ahead_mask,\n",
        "            return_attention_scores = True\n",
        "        )\n",
        "\n",
        "        # first residual connection and layer norm\n",
        "        norm_layer_out_1 = self.layernorm1(multi_attn_out_1 + x)\n",
        "\n",
        "        # multi head attention layer\n",
        "        multi_attn_out_2, attention_weights = self.mha2(\n",
        "            query = norm_layer_out_1,\n",
        "            key = encoder_output,\n",
        "            value = encoder_output,\n",
        "            attention_mask = padding_mask,\n",
        "            return_attention_scores=True\n",
        "        )\n",
        "\n",
        "        # second residual connection and layer norm\n",
        "        norm_layer_out_2 = self.layernorm2(multi_attn_out_2 + norm_layer_out_1)\n",
        "\n",
        "        # feed forward nn\n",
        "        ffn_output = self.ffn(norm_layer_out_2)\n",
        "\n",
        "        # dropout layer\n",
        "        ffn_output = self.dropout(ffn_output, training = is_training)\n",
        "\n",
        "        output = self.layernorm3(ffn_output + norm_layer_out_2)\n",
        "\n",
        "        return output, masked_attention_weights, attention_weights"
      ],
      "metadata": {
        "id": "8c3SKvbuyXpn"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = tf.random.uniform((1,3,5))\n",
        "\n",
        "dec = DecoderLayer(num_heads = 1,\n",
        "                 embedding_dim = 5,\n",
        "                 fully_connected_dim = 120)\n",
        "\n",
        "dec_out, masked_attn_weights, attn_weights = dec(q,\n",
        "                                                 encoder_output = encoder_out,\n",
        "                                                 is_training = True,\n",
        "                                                 look_ahead_mask = None,\n",
        "                                                 padding_mask = None)\n",
        "\n",
        "print(f\"q has shape:{q.shape}\")\n",
        "print(f\"Output of encoder has shape:{encoder_out.shape}\\n\")\n",
        "print(f\"Output of decoder layer has shape:{dec_out.shape}\")\n",
        "print(f\"masked attetion Weights has shape:{masked_attn_weights.shape}\")\n",
        "print(f\"attetion Weights has shape:{attn_weights.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol_c2BKIBH9k",
        "outputId": "b7bb5d74-c311-4c3e-91e6-257665c2db74"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "q has shape:(1, 3, 5)\n",
            "Output of encoder has shape:(1, 2, 10)\n",
            "\n",
            "Output of decoder layer has shape:(1, 3, 5)\n",
            "masked attetion Weights has shape:(1, 1, 3, 3)\n",
            "attetion Weights has shape:(1, 1, 3, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "\n",
        "    \"full decoder\"\n",
        "\n",
        "    def __init__(self,num_layers,embedding_dim,num_heads,\n",
        "                      fully_connected_dim,target_vocab_size,\n",
        "                      maximum_position_encoding,\n",
        "                      dropout_rate=0.1, layernorm_eps=1e-6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(\n",
        "            input_dim = target_vocab_size,\n",
        "            output_dim = self.embedding_dim\n",
        "        )\n",
        "\n",
        "        self.pos_encoding = positional_encoding(\n",
        "            positions = maximum_position_encoding,\n",
        "            d_model = self.embedding_dim\n",
        "        )\n",
        "\n",
        "        # repreating decoder layer for certain num of layers\n",
        "        self.decoder_layers = [\n",
        "            DecoderLayer(\n",
        "                self.embedding_dim,\n",
        "                num_heads, fully_connected_dim,\n",
        "                dropout_rate=0.1, layernorm_eps=1e-06)\n",
        "\n",
        "            for _ in range(self.num_layers)\n",
        "            ]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, encoder_output, is_training, look_ahead_mask, padding_mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        all_attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # this scaling process helps maintain a good balance between\n",
        "        # the learned embeddings and the fixed positional encodings\n",
        "        # because the embedding is a slightly smaller than the positional encoding values\n",
        "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
        "\n",
        "        # add positional encoding\n",
        "        x += self.pos_encoding[:,:seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training = is_training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, masked_attention_weights, attention_weights = self.decoder_layers[i](\n",
        "                x, encoder_output, is_training = is_training,\n",
        "                look_ahead_mask = look_ahead_mask,\n",
        "                padding_mask = padding_mask\n",
        "            )\n",
        "\n",
        "        all_attention_weights['decoder_layer{}_block1_self_att'.format(i+1)] = masked_attention_weights\n",
        "        all_attention_weights['decoder_layer{}_block2_decenc_att'.format(i+1)] = attention_weights\n",
        "\n",
        "        return x, all_attention_weights"
      ],
      "metadata": {
        "id": "y32-bvpLrO_z"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function!\n",
        "n_layers = 5\n",
        "emb_d = 13\n",
        "n_heads = 17\n",
        "fully_connected_dim = 16\n",
        "target_vocab_size = 300\n",
        "maximum_position_encoding = 6\n",
        "\n",
        "x = np.array([[3, 2, 1, 1], [2, 1, 1, 0], [2, 1, 1, 0]])\n",
        "\n",
        "encoder_test_output = tf.convert_to_tensor(np.random.rand(3, 7, 9))\n",
        "\n",
        "look_ahead_mask = create_look_ahead_mask(x.shape[1])\n",
        "\n",
        "decoder_test = Decoder(\n",
        "    n_layers, emb_d, n_heads, fully_connected_dim, target_vocab_size,maximum_position_encoding)\n",
        "\n",
        "outd, att_weights = decoder_test(\n",
        "    x, encoder_test_output, is_training = False, look_ahead_mask = look_ahead_mask, padding_mask = None)\n",
        "\n",
        "print(f\"Using num_layers={n_layers}, embedding_dim={emb_d} and num_heads={n_heads}:\\n\")\n",
        "print(f\"x has shape:{x.shape}\")\n",
        "print(f\"Output of encoder has shape:{encoder_test_output.shape}\\n\")\n",
        "\n",
        "print(f\"Output of decoder has shape:{outd.shape}\\n\")\n",
        "\n",
        "print(\"Attention weights:\")\n",
        "for name, tensor in att_weights.items():\n",
        "    print(f\"{name} has shape:{tensor.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5N5cg2augyR",
        "outputId": "e4224dbe-1b5b-4129-e2e3-3a803c678af1"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using num_layers=5, embedding_dim=13 and num_heads=17:\n",
            "\n",
            "x has shape:(3, 4)\n",
            "Output of encoder has shape:(3, 7, 9)\n",
            "\n",
            "Output of decoder has shape:(3, 4, 13)\n",
            "\n",
            "Attention weights:\n",
            "decoder_layer5_block1_self_att has shape:(3, 17, 4, 4)\n",
            "decoder_layer5_block2_decenc_att has shape:(3, 17, 4, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer"
      ],
      "metadata": {
        "id": "sPom3AHZwmFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_layers,\n",
        "                 input_vocab_size,\n",
        "                 target_vocab_size,\n",
        "                 embedding_dim,\n",
        "                 maximum_position_encoding_input,\n",
        "                 maximum_position_encoding_target,\n",
        "                 num_heads,\n",
        "                 fully_connected_dim,\n",
        "                 dropout_rate=0.1,\n",
        "                 layernorm_eps=1e-06):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers = num_layers,\n",
        "                               vocab_size = input_vocab_size,\n",
        "                               embedding_dim = embedding_dim,\n",
        "                               maximum_position_encoding = maximum_position_encoding_input,\n",
        "                               num_heads = num_heads,\n",
        "                               fully_connected_dim = fully_connected_dim,\n",
        "                               dropout_rate = dropout_rate,\n",
        "                               layernorm_eps = layernorm_eps\n",
        "        )\n",
        "\n",
        "        self.decoder = Decoder(num_layers = num_layers,\n",
        "                               embedding_dim = embedding_dim,\n",
        "                               num_heads = num_heads,\n",
        "                               fully_connected_dim = fully_connected_dim,\n",
        "                               target_vocab_size = target_vocab_size,\n",
        "                               maximum_position_encoding = maximum_position_encoding_target,\n",
        "                               dropout_rate = dropout_rate,\n",
        "                               layernorm_eps = layernorm_eps\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        self.fc = tf.keras.layers.Dense(\n",
        "            target_vocab_size,\n",
        "            activation = \"softmax\"\n",
        "        )\n",
        "\n",
        "\n",
        "    def call(self,input, target, is_training,\n",
        "             enc_padding_mask, dec_padding_mask,\n",
        "             look_ahead_mask):\n",
        "\n",
        "        enc_out = self.encoder(input,\n",
        "                               is_training = is_training,\n",
        "                               mask = enc_padding_mask\n",
        "        )\n",
        "\n",
        "        dec_out, _ = self.decoder(target,\n",
        "                                  enc_out,\n",
        "                                  is_training = is_training,\n",
        "                                  look_ahead_mask = look_ahead_mask,\n",
        "                                  padding_mask = dec_padding_mask\n",
        "        )\n",
        "\n",
        "        output = self.fc(dec_out)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "r9c1lmK3jnvo"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = tf.constant([[2, 3, 1, 3, 0, 0, 0]])\n",
        "tar = tf.constant([[1, 3, 4, 0, 0, 0, 0]])\n",
        "\n",
        "trans = Transformer(\n",
        "    num_layers=1,\n",
        "    input_vocab_size=5,\n",
        "    target_vocab_size=6,\n",
        "    embedding_dim=10,\n",
        "    maximum_position_encoding_input=10,\n",
        "    maximum_position_encoding_target = 10,\n",
        "    num_heads=10,\n",
        "    fully_connected_dim=13\n",
        "    )\n",
        "\n",
        "enc_padding_mask = create_padding_mask(inp)\n",
        "dec_padding_mask = create_padding_mask(tar)\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[1])\n",
        "\n",
        "trans(inp, tar, is_training = False,\n",
        "      enc_padding_mask = enc_padding_mask,\n",
        "      dec_padding_mask = dec_padding_mask,\n",
        "      look_ahead_mask = look_ahead_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6VJr9632-ys",
        "outputId": "99e6fe11-4159-4b5b-affa-9b380c853ba6"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'encoder_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 7, 6), dtype=float32, numpy=\n",
              "array([[[0.01487851, 0.20799032, 0.16125268, 0.33717978, 0.07287869,\n",
              "         0.20582001],\n",
              "        [0.03978156, 0.20249669, 0.25221854, 0.2504698 , 0.04786408,\n",
              "         0.20716928],\n",
              "        [0.06639344, 0.22112691, 0.19102435, 0.27094004, 0.03723403,\n",
              "         0.21328126],\n",
              "        [0.07335594, 0.25044033, 0.11506843, 0.30594125, 0.04390745,\n",
              "         0.21128659],\n",
              "        [0.06299673, 0.23691863, 0.06678327, 0.35449   , 0.06316341,\n",
              "         0.21564794],\n",
              "        [0.04523607, 0.21091118, 0.04452794, 0.3888606 , 0.0956915 ,\n",
              "         0.21477267],\n",
              "        [0.05040847, 0.23726067, 0.06002739, 0.32277077, 0.11378585,\n",
              "         0.21574683]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialize the Model\n"
      ],
      "metadata": {
        "id": "XZc-xsO7PITJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 2\n",
        "embedding_dim = 128\n",
        "fully_connected_dim = 128\n",
        "num_heads = 2\n",
        "positional_encoding_length = 256\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "transformer = Transformer(\n",
        "    num_layers = num_layers,\n",
        "    input_vocab_size = vocab_size,\n",
        "    target_vocab_size = vocab_size,\n",
        "    embedding_dim = embedding_dim,\n",
        "    maximum_position_encoding_input = positional_encoding_length,\n",
        "    maximum_position_encoding_target = positional_encoding_length,\n",
        "    num_heads = num_heads,\n",
        "    fully_connected_dim = fully_connected_dim\n",
        ")"
      ],
      "metadata": {
        "id": "dalbPJChAbRi"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare for Training the Model"
      ],
      "metadata": {
        "id": "dBPU7zama70k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "    def __init__(self, d_model, warmup_steps = 4000):\n",
        "\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = tf.cast(d_model, dtype=tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "\n",
        "        step = tf.cast(step, dtype=tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "learning_rate = CustomSchedule(embedding_dim)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "id": "YmPodIUBQ1Mf"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps=500000\n",
        "\n",
        "plt.plot(learning_rate(range(steps)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "sTvJ8oUcmVGj",
        "outputId": "85f4b991-7e3e-45b0-a8be-61624745ae60"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7b9603129bd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(true, pred):\n",
        "\n",
        "    loss_func = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits = False, # softmax used\n",
        "        reduction = 'none'\n",
        "    )\n",
        "\n",
        "    # mask to ignore padding in y_true\n",
        "    mask = tf.cast(tf.logical_not(tf.equal(true, 0)), loss_func.dtype)\n",
        "\n",
        "    loss = loss_func(true, pred)\n",
        "\n",
        "    # apply mask\n",
        "    loss *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss, axis = -1) / tf.reduce_sum(mask , axis=-1)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
        "\n",
        "losses = []"
      ],
      "metadata": {
        "id": "yv6-zIodqIBh"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(model, input, target):\n",
        "\n",
        "    \"\"\"custom training function alternative to using model.compile() and model.fit(),\n",
        "        but with added extra flexibility.\"\"\"\n",
        "\n",
        "    # prepair target\n",
        "    tar_inp = target[:, :-1] # input target wothout EOS\n",
        "    tar_real = target[:, 1:] # actual target without SOS\n",
        "\n",
        "    # maskes\n",
        "    enc_padding_mask = create_padding_mask(input)\n",
        "    dec_padding_mask = create_padding_mask(input)\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar_inp)[1]) # target seq_len\n",
        "\n",
        "    # TensorFlow starts recording all operations that involve tensors\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        # Forward Pass\n",
        "        predictions = model(\n",
        "            input,\n",
        "            tar_inp,\n",
        "            is_training=True,\n",
        "            enc_padding_mask = enc_padding_mask,\n",
        "            dec_padding_mask = dec_padding_mask,\n",
        "            look_ahead_mask = look_ahead_mask\n",
        "        )\n",
        "\n",
        "        # loss\n",
        "        loss = masked_loss(tar_real, predictions)\n",
        "\n",
        "    # After the block ends, use tape.gradient() to automatically compute gradients\n",
        "    gradient = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
        "\n",
        "    # update loss\n",
        "    train_loss(loss)"
      ],
      "metadata": {
        "id": "QOV_PDW0Vdjg"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_step(transformer, list(dataset.take(1))[0][0], list(dataset.take(1))[0][1])"
      ],
      "metadata": {
        "id": "OJNbbjJ3JMpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f30168-d842-4dfa-85cc-7f16c1223f36"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'encoder_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summarization\n"
      ],
      "metadata": {
        "id": "xlA55_edSTCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def next_word(model, encoder_input, output):\n",
        "\n",
        "    \"A function for predicting the next word in the summary\"\n",
        "\n",
        "    # used in encoder multi head attention layer\n",
        "    enc_padding_mask = create_padding_mask(encoder_input)\n",
        "\n",
        "    # used in decoder masked multi head attention layer\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(output)[1])\n",
        "\n",
        "    # used in decoder multi head attention layer\n",
        "    # we need to pad the encoder positions that comes from the encoder\n",
        "    dec_padding_mask = create_padding_mask(encoder_input)\n",
        "\n",
        "    predictions = model(\n",
        "        encoder_input,\n",
        "        output,\n",
        "        is_training = False,\n",
        "        enc_padding_mask = enc_padding_mask,\n",
        "        dec_padding_mask = dec_padding_mask,\n",
        "        look_ahead_mask = look_ahead_mask)\n",
        "\n",
        "    # select the hidden state for the last token\n",
        "    predictions = predictions[:, -1:, :]\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions ,axis = -1), tf.int32)\n",
        "\n",
        "    return predicted_id"
      ],
      "metadata": {
        "id": "bpNWLrBGoxgg"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_document = tokenizer.texts_to_sequences([\"see you\"])\n",
        "input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "encoder_input = tf.expand_dims(input_document[0], 0)\n",
        "\n",
        "output = tf.expand_dims([tokenizer.word_index[\"[SOS]\"]], 0)\n",
        "\n",
        "predicted_token = next_word(transformer, encoder_input, output)\n",
        "print(f\"Predicted token: {predicted_token}\")\n",
        "\n",
        "predicted_word = tokenizer.sequences_to_texts(predicted_token.numpy())[0]\n",
        "print(f\"Predicted word: {predicted_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfxGgnQxSZ7a",
        "outputId": "2fa9be74-a806-4a97-8780-bbd0a2ceebe8"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted token: [[30039]]\n",
            "Predicted word: puh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(model, input_document, decoder_maxlen):\n",
        "\n",
        "    \"A function for summarization using the transformer model\"\n",
        "\n",
        "    input_document = tokenizer.texts_to_sequences([input_document])\n",
        "\n",
        "    input_document = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        input_document,\n",
        "        maxlen = encoder_maxlen,\n",
        "        padding = 'post',\n",
        "        truncating = 'post'\n",
        "    )\n",
        "\n",
        "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
        "\n",
        "    output = tf.expand_dims([tokenizer.word_index[\"[SOS]\"]], 0)\n",
        "\n",
        "    for i in range(decoder_maxlen):\n",
        "\n",
        "        predicted_id = next_word(model, encoder_input, output)\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "        if predicted_id == tokenizer.word_index[\"[EOS]\"]:\n",
        "            break\n",
        "\n",
        "    return tokenizer.sequences_to_texts(output.numpy())[0]"
      ],
      "metadata": {
        "id": "ry8mm4n8Wf5X"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set_example = 0\n",
        "\n",
        "# Check a summary of a document from the training set\n",
        "print('Training set example:')\n",
        "print(document[training_set_example])\n",
        "print('\\nHuman written summary:')\n",
        "print(summary[training_set_example])\n",
        "print('\\nModel written summary:')\n",
        "summarize(transformer, document[training_set_example], decoder_maxlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "IvAKlXt4Wfxr",
        "outputId": "3b7e65d7-3dc3-4886-ac1d-601501be6709"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set example:\n",
            "[SOS] amanda: i baked cookies. do you want some? jerry: sure! amanda: i'll bring you tomorrow :-) [EOS]\n",
            "\n",
            "Human written summary:\n",
            "[SOS] amanda baked cookies and will bring jerry some tomorrow. [EOS]\n",
            "\n",
            "Model written summary:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[SOS] puh promptly terminates gr8 frittur ozan laaaast stapler loooong birthady flavoured towns shocks cleaners leonard's primal birthady ozan valentines maintains pigment morality decade decade kawasaki case floor extra determination determination determination cartman moldova kendrick robinson ddi chris'es robinson isnt sloooow counseling determination waits waits aaaa assesment wirelessly valentines dilan convesation\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the model"
      ],
      "metadata": {
        "id": "qfLHNP6Y0d9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "number_of_batches = len(list(dataset))\n",
        "\n",
        "test_example = 0\n",
        "true_summary = summary_test[test_example]\n",
        "true_document = document_test[test_example]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    start = time.time()\n",
        "    train_loss.reset_state()\n",
        "\n",
        "    for batch, (inp, tar) in enumerate(dataset):\n",
        "\n",
        "        train_step(transformer, inp, tar)\n",
        "\n",
        "    print (f'Epoch {epoch + 1}, Loss {train_loss.result():.4f}')\n",
        "\n",
        "    losses.append(train_loss.result())\n",
        "\n",
        "    print (f'Time taken for one epoch: {time.time() - start} sec')\n",
        "    print('Example summarization on the test set:')\n",
        "    print('  True summarization:')\n",
        "    print(f'    {true_summary}')\n",
        "    print('  Predicted summarization:')\n",
        "    print(f'    {summarize(transformer, true_document, decoder_maxlen)}\\n')"
      ],
      "metadata": {
        "id": "zQ5J5nkkYXS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "112be790-df48-4ebb-c4cb-ef0fea036c8b"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss 9.9260\n",
            "Time taken for one epoch: 32.32589292526245 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] [EOS]\n",
            "\n",
            "Epoch 2, Loss 7.7242\n",
            "Time taken for one epoch: 27.580942630767822 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] [EOS]\n",
            "\n",
            "Epoch 3, Loss 6.6189\n",
            "Time taken for one epoch: 27.253843545913696 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] is going to the [EOS]\n",
            "\n",
            "Epoch 4, Loss 5.9556\n",
            "Time taken for one epoch: 27.101184844970703 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] the new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new\n",
            "\n",
            "Epoch 5, Loss 5.4914\n",
            "Time taken for one epoch: 27.192826986312866 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] the new new new new new new job [EOS]\n",
            "\n",
            "Epoch 6, Loss 5.1883\n",
            "Time taken for one epoch: 27.159050226211548 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] mike is going to go to the party [EOS]\n",
            "\n",
            "Epoch 7, Loss 4.9237\n",
            "Time taken for one epoch: 27.143218278884888 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] mike is going to go with her [EOS]\n",
            "\n",
            "Epoch 8, Loss 4.6412\n",
            "Time taken for one epoch: 27.199764251708984 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] hannah has just got her phone with her [EOS]\n",
            "\n",
            "Epoch 9, Loss 4.3406\n",
            "Time taken for one epoch: 27.1485595703125 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] hannah is angry at the number and she will have a number [EOS]\n",
            "\n",
            "Epoch 10, Loss 4.0364\n",
            "Time taken for one epoch: 27.122023344039917 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] hannah is going to take care of the number to him [EOS]\n",
            "\n",
            "Epoch 11, Loss 3.7270\n",
            "Time taken for one epoch: 27.144610166549683 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] amanda is at work [EOS]\n",
            "\n",
            "Epoch 12, Loss 3.4274\n",
            "Time taken for one epoch: 27.14978313446045 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] amanda is at work [EOS]\n",
            "\n",
            "Epoch 13, Loss 3.1354\n",
            "Time taken for one epoch: 27.160919189453125 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] hannah will text hannah to go to the park today [EOS]\n",
            "\n",
            "Epoch 14, Loss 2.8672\n",
            "Time taken for one epoch: 27.186405181884766 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] amanda is going to buy flowers with amanda [EOS]\n",
            "\n",
            "Epoch 15, Loss 2.6142\n",
            "Time taken for one epoch: 27.2181236743927 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] amanda will try to find out after she doesn't want to go to the park [EOS]\n",
            "\n",
            "Epoch 16, Loss 2.3857\n",
            "Time taken for one epoch: 27.235374450683594 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] amanda will check if she doesn't feel well [EOS]\n",
            "\n",
            "Epoch 17, Loss 2.1718\n",
            "Time taken for one epoch: 27.226278066635132 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] amanda is worried about amanda and wants to go together [EOS]\n",
            "\n",
            "Epoch 18, Loss 1.9800\n",
            "Time taken for one epoch: 27.195590257644653 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] amanda is looking forward to amanda [EOS]\n",
            "\n",
            "Epoch 19, Loss 1.7753\n",
            "Time taken for one epoch: 27.188947916030884 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] amanda will let amanda know when she was at the park [EOS]\n",
            "\n",
            "Epoch 20, Loss 1.5857\n",
            "Time taken for one epoch: 27.180142641067505 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] amanda is going to get caught [EOS]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "NUcTjfNUmUkL",
        "outputId": "2963a4a1-3c29-465e-d3f5-7a2f976bbe36"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "metadata": {},
          "execution_count": 109
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"model.weights.h5\""
      ],
      "metadata": {
        "id": "QzaZXUKmJuey"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformer.save_weights(save_dir)"
      ],
      "metadata": {
        "id": "4BP5rlqK8ZlW"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.load_weights(save_dir)"
      ],
      "metadata": {
        "id": "hJkVNHQhKBT1"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set_example = 41\n",
        "\n",
        "# Check a summary of a document from the training set\n",
        "print('Training set example:')\n",
        "print(document_test[training_set_example])\n",
        "print('\\nHuman written summary:')\n",
        "print(summary_test[training_set_example])\n",
        "print('\\nModel written summary:')\n",
        "print(summarize(transformer, document_test[training_set_example], decoder_maxlen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OpE6p3R3yap",
        "outputId": "ad8d153d-5fc6-4f89-d3d0-662661556300"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set example:\n",
            "[SOS] frank: son, will you come home this weekend? son: not sure yet. something happened? frank: of course not. your mother miss you. son: i miss her too. frank: so will you com? son: i will try. frank: good, i will tell your mother that you will come son: oh, dad.. ok i will come. [EOS]\n",
            "\n",
            "Human written summary:\n",
            "[SOS] son is coming to see his parents' this weekend. [EOS]\n",
            "\n",
            "Model written summary:\n",
            "[SOS] frank will come home to visit his mother [EOS]\n"
          ]
        }
      ]
    }
  ]
}