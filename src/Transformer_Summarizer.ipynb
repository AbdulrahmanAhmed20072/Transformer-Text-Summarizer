{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PDmSrq1Xv-zH",
        "XCGjt2f0q5Jc",
        "SUlP5YqYt97C",
        "PA6qPHI01MzV",
        "sPom3AHZwmFi",
        "XZc-xsO7PITJ"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import the Dataset\n"
      ],
      "metadata": {
        "id": "ArVLRskqvfJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow==2.18.0 numpy==1.26.4 pandas==2.2.2 rouge-score==0.1.2"
      ],
      "metadata": {
        "id": "aGfMext9-b19"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "from utils_transformer import get_train_test_data, preprocess\n",
        "\n",
        "tf.keras.utils.set_random_seed(10)"
      ],
      "metadata": {
        "id": "R5T6KMkmcYRj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = get_train_test_data(\".\")"
      ],
      "metadata": {
        "id": "2qM8RcSZL4qy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocess the data"
      ],
      "metadata": {
        "id": "OemuUGMAvlXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_summary, example_dialogue = train_data.iloc[10]\n",
        "\n",
        "print(f\"dialogue:\\n{example_dialogue}\\n\")\n",
        "print(f\"summary:\\n{example_summary}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj4TTvmrODfi",
        "outputId": "2f2c9b8a-d121-4195-8147-12f857928321"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dialogue:\n",
            "Lucas: Hey! How was your day?\r\n",
            "Demi: Hey there! \r\n",
            "Demi: It was pretty fine, actually, thank you!\r\n",
            "Demi: I just got promoted! :D\r\n",
            "Lucas: Whoa! Great news!\r\n",
            "Lucas: Congratulations!\r\n",
            "Lucas: Such a success has to be celebrated.\r\n",
            "Demi: I agree! :D\r\n",
            "Demi: Tonight at Death & Co.?\r\n",
            "Lucas: Sure!\r\n",
            "Lucas: See you there at 10pm?\r\n",
            "Demi: Yeah! See you there! :D\n",
            "\n",
            "summary:\n",
            "Demi got promoted. She will celebrate that with Lucas at Death & Co at 10 pm.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary, document = preprocess(train_data)\n",
        "summary_test, document_test = preprocess(test_data[:200])"
      ],
      "metadata": {
        "id": "E2vjPAfWOH1S"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters = '!\"#$%&()*+,-./:;<=>?@\\\\^_`{|}~\\t\\n'\n",
        "oov_token = '[UNK]'\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    filters = filters,\n",
        "    lower = False,\n",
        "    oov_token = oov_token\n",
        "    )\n",
        "\n",
        "documents_and_summary = pd.concat([document, summary], ignore_index = True)\n",
        "\n",
        "# create the vocabulary\n",
        "tokenizer.fit_on_texts(documents_and_summary)\n",
        "\n",
        "# convert words to vectors\n",
        "inputs = tokenizer.texts_to_sequences(document)\n",
        "targets = tokenizer.texts_to_sequences(summary)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(f'Size of vocabulary: {vocab_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7SJYTFgQdqB",
        "outputId": "fc7f0d6e-b49d-42e8-b550-38f97251cf0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 34250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_maxlen = 150\n",
        "decoder_maxlen = 50\n",
        "\n",
        "# apply padding\n",
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences = inputs,\n",
        "    maxlen = encoder_maxlen,\n",
        "    padding = 'post',\n",
        "    truncating = 'post')\n",
        "\n",
        "targets = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences = targets,\n",
        "    maxlen = decoder_maxlen,\n",
        "    padding = 'post',\n",
        "    truncating = 'post')"
      ],
      "metadata": {
        "id": "NcmeNa0HUdKU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert vectors to float32\n",
        "inputs = tf.cast(inputs, tf.float32)\n",
        "targets = tf.cast(targets, tf.float32)"
      ],
      "metadata": {
        "id": "kGo9opQjUiEZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 10000\n",
        "batch_size = 64\n",
        "\n",
        "# create the dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    tensors = (inputs, targets)).shuffle(BUFFER_SIZE).batch(batch_size)"
      ],
      "metadata": {
        "id": "Le4wOnR4WhSo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataset.take(1):\n",
        "    print(f\"first input sample shape: {i[0].shape}\")\n",
        "    print(f\"first target sample shape: {i[1].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLLKmoDSXmAH",
        "outputId": "6748af56-9a8c-4112-a7f8-edb875cf66e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first input sample shape: (64, 150)\n",
            "first target sample shape: (64, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Positional Encoding"
      ],
      "metadata": {
        "id": "PDmSrq1Xv-zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(positions, d_model):\n",
        "\n",
        "    position = np.arange(positions)[:, np.newaxis]\n",
        "    k = np.arange(d_model)[np.newaxis, :]\n",
        "    i = k // 2\n",
        "\n",
        "    # initialize a matrix angle_rads of all the angles\n",
        "    angle_rates = 1 / np.power(10000, (2 * i) / np.float32(d_model))\n",
        "    angle_rads = position * angle_rates\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "8qMi6xqQZrZc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Masking\n"
      ],
      "metadata": {
        "id": "baZ9PqpFv2MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(decoder_token_ids):\n",
        "\n",
        "    \"Creates a matrix mask for the padding cells\"\n",
        "\n",
        "    seq = 1 - tf.cast(tf.equal(decoder_token_ids, 0), decoder_token_ids.dtype)\n",
        "\n",
        "    return seq[:, tf.newaxis, :]"
      ],
      "metadata": {
        "id": "a-IfDBs3t45M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_padding_mask(tf.constant([[1,2,0],\n",
        "                                 [3,0,0]],dtype = tf.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W398tRdNwjAc",
        "outputId": "87ecb1b6-3c2b-409a-e659-4fa1404b5a00"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1, 3), dtype=float32, numpy=\n",
              "array([[[1., 1., 0.]],\n",
              "\n",
              "       [[1., 0., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(sequence_length):\n",
        "\n",
        "    \"Returns a lower triangular matrix filled with ones\"\n",
        "\n",
        "    ones = tf.ones((1, sequence_length, sequence_length))\n",
        "\n",
        "    # num_lower = -1 means fill under diagonal with ones,\n",
        "    # num_upper = 0 means let upper the diagonal with zeros\n",
        "    return tf.linalg.band_part(ones, num_lower = -1, num_upper = 0)"
      ],
      "metadata": {
        "id": "S6DKN4gqwxau"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1,2,0], [3,0,0], [1,2,1]], dtype = tf.float32)\n",
        "\n",
        "create_look_ahead_mask(a.shape[-2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_gdeP0-z0NJ",
        "outputId": "f25be3e7-cfae-4fc8-aefd-676496fc8a9b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\n",
              "array([[[1., 0., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 1.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#self-attention"
      ],
      "metadata": {
        "id": "XCGjt2f0q5Jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "\n",
        "    align = tf.matmul(q, k, transpose_b = True)\n",
        "\n",
        "    dk = tf.cast(k.shape[-1], align.dtype)\n",
        "    scaled_align = align / tf.math.sqrt(dk)\n",
        "\n",
        "    # musk should be applied before softmax\n",
        "    if mask is not None:\n",
        "        scaled_align += (1.0 - mask) * -1e9\n",
        "\n",
        "    weights = tf.nn.softmax(scaled_align)\n",
        "\n",
        "    context = tf.matmul(weights, v)\n",
        "\n",
        "    return context, weights"
      ],
      "metadata": {
        "id": "I41x3D1-0HWP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = tf.constant([[1,2,0], [3,0,0], [1,2,1]], dtype = tf.float32)\n",
        "\n",
        "k = tf.constant([[1,2,0], [3,0,0], [1,2,1]], dtype = tf.float32)\n",
        "\n",
        "v = tf.constant([[1,2,0], [3,0,0], [1,2,1]], dtype = tf.float32)\n",
        "\n",
        "scaled_dot_product_attention(q, k, v, None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_0POlTwXjt6",
        "outputId": "17af88b0-e927-4c37-a73d-9e12fc52356b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              " array([[1.2722516 , 1.7277484 , 0.4319371 ],\n",
              "        [2.8821719 , 0.11782812, 0.02945703],\n",
              "        [1.203556  , 1.7964439 , 0.57527304]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              " array([[0.4319371 , 0.1361258 , 0.4319371 ],\n",
              "        [0.02945703, 0.9410859 , 0.02945703],\n",
              "        [0.32294896, 0.10177799, 0.57527304]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the function\n",
        "q = np.array([[1, 1, 0, 1],\n",
        "              [0, 1, 1, 1],\n",
        "              [1, 0, 1, 1]]).astype(np.float32)\n",
        "\n",
        "k = np.array([[1, 1, 0, 1],\n",
        "              [1, 0, 1, 1],\n",
        "              [1, 1, 1, 0],\n",
        "              [0, 0, 0, 1],\n",
        "              [0, 1, 0, 1]]).astype(np.float32)\n",
        "\n",
        "v = np.array([[0, 0],\n",
        "              [1, 0],\n",
        "              [1, 0],\n",
        "              [1, 1],\n",
        "              [1, 1]]).astype(np.float32)\n",
        "\n",
        "mask = np.array([[[0, 1, 0, 1, 1],\n",
        "                  [1, 0, 0, 1, 1],\n",
        "                  [1, 1, 0, 1, 1]]])\n",
        "\n",
        "ou, atw = scaled_dot_product_attention(q, k, v, mask)\n",
        "ou = np.around(ou, decimals=2)\n",
        "atw = np.around(atw, decimals=2)\n",
        "\n",
        "print(f\"Output:\\n {ou}\")\n",
        "print(f\"\\nAttention weigths:\\n {atw}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff-Dpx2cXnxq",
        "outputId": "b0d65aa7-681b-4556-bde7-09254239415e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            " [[[1.   0.62]\n",
            "  [0.62 0.62]\n",
            "  [0.74 0.31]]]\n",
            "\n",
            "Attention weigths:\n",
            " [[[0.   0.38 0.   0.23 0.38]\n",
            "  [0.38 0.   0.   0.23 0.38]\n",
            "  [0.26 0.43 0.   0.16 0.16]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoder"
      ],
      "metadata": {
        "id": "SUlP5YqYt97C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def FullyConnected(embedding_dim, fully_connected_dim):\n",
        "\n",
        "    ffnn = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(fully_connected_dim, activation='relu'),\n",
        "        tf.keras.layers.Dense(embedding_dim)])\n",
        "\n",
        "    return ffnn"
      ],
      "metadata": {
        "id": "Miqk9W_gbSMC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, num_heads, embedding_dim,\n",
        "                 fully_connected_dim, dropout_rate = 0.1,\n",
        "                 layernorm_eps = 1e-6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(\n",
        "                num_heads = num_heads,\n",
        "                key_dim = embedding_dim,\n",
        "                dropout = dropout_rate,\n",
        "            )\n",
        "\n",
        "        self.ffn = FullyConnected(\n",
        "                embedding_dim,\n",
        "                fully_connected_dim\n",
        "            )\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = layernorm_eps)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = layernorm_eps)\n",
        "\n",
        "        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def __call__(self, x, is_training, mask):\n",
        "\n",
        "        # since we are in encoder, use the same i/p for qkv\n",
        "        self_mha_output = self.mha(\n",
        "            query = x, key = x, value = x, attention_mask = mask)\n",
        "\n",
        "        # residual connection and normalization\n",
        "        skip_x_attention = self.layernorm1(x + self_mha_output)\n",
        "\n",
        "        # feed forward nn\n",
        "        ffn_output = self.ffn(skip_x_attention)\n",
        "\n",
        "        # apply dropout just for training\n",
        "        ffn_output = self.dropout_ffn(ffn_output, training = is_training)\n",
        "\n",
        "        # another residual connection and normalization\n",
        "        encoder_layer_out = self.layernorm2(skip_x_attention + ffn_output)\n",
        "\n",
        "        return encoder_layer_out"
      ],
      "metadata": {
        "id": "IEqJKUAP6o1i"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.random.uniform((1,3,5))\n",
        "\n",
        "E = EncoderLayer(num_heads = 1,\n",
        "                 embedding_dim = 5,\n",
        "                 fully_connected_dim= 120)\n",
        "\n",
        "E(x = x, is_training = True, mask = None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFg4WIqRZY3C",
        "outputId": "c770716b-99cb-407d-f350-07fd4a9782a7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3, 5), dtype=float32, numpy=\n",
              "array([[[ 0.7081839 ,  0.41457322, -1.5866754 ,  1.1543071 ,\n",
              "         -0.6903888 ],\n",
              "        [ 1.313329  , -0.37334985, -1.6875824 ,  0.30907148,\n",
              "          0.43853182],\n",
              "        [ 1.1260601 , -0.1944412 , -0.70851934,  1.1468799 ,\n",
              "         -1.3699793 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "\n",
        "    \"\"\"\n",
        "      the full encoder starts with passing the i/p to embedding layer\n",
        "      and ends with a contextual representation for the sequance\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_layers, vocab_size,\n",
        "                 embedding_dim, maximum_position_encoding,\n",
        "                 num_heads, fully_connected_dim,\n",
        "                 dropout_rate=0.1, layernorm_eps=1e-6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(\n",
        "            input_dim = vocab_size,\n",
        "            output_dim = embedding_dim,\n",
        "            mask_zero = True # ignaoring 0 in calcualtions\n",
        "        )\n",
        "\n",
        "        self.pos_encoding = positional_encoding(\n",
        "            maximum_position_encoding,\n",
        "            embedding_dim\n",
        "        )\n",
        "\n",
        "        # repreating encoder layer for certain num of layers\n",
        "        self.enc_layer = [\n",
        "            EncoderLayer(num_heads,\n",
        "                         embedding_dim,\n",
        "                         fully_connected_dim,\n",
        "                         dropout_rate,\n",
        "                         layernorm_eps)\n",
        "\n",
        "            for _ in range(num_layers)\n",
        "            ]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, is_training, mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # this scaling process helps maintain a good balance between\n",
        "        # the learned embeddings and the fixed positional encodings\n",
        "        # because the embedding is a slightly smaller than the positional encoding values\n",
        "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
        "\n",
        "        # add positional encoding values\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=is_training)\n",
        "\n",
        "        # iterate over encoder layer for n times\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layer[i](x, is_training, mask)\n",
        "\n",
        "        return x # (batch_size, input_seq_len, embedding_dim)"
      ],
      "metadata": {
        "id": "Jmt0Ul6-_miu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.random.uniform((1,2))\n",
        "\n",
        "E = Encoder(num_layers=2, vocab_size=vocab_size,\n",
        "                 embedding_dim=10,maximum_position_encoding=100,\n",
        "                 num_heads=8, fully_connected_dim=150,\n",
        "                 dropout_rate=0.1, layernorm_eps=1e-6)\n",
        "\n",
        "encoder_out = E(x, is_training = True, mask= None)\n",
        "encoder_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G9tNl0UoDflS",
        "outputId": "773d4703-1c17-4906-cd88-4f7fa4342e59"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 10), dtype=float32, numpy=\n",
              "array([[[-0.30631414,  1.0099329 , -1.2527146 ,  0.72792435,\n",
              "         -0.4140447 ,  0.3989549 , -1.2532282 ,  0.41933027,\n",
              "         -1.162495  ,  1.8326545 ],\n",
              "        [-0.20135403, -0.26914924, -0.4888366 ,  0.5466636 ,\n",
              "         -0.6971479 ,  0.9217518 , -1.1409347 ,  0.2441242 ,\n",
              "         -1.1987865 ,  2.2836695 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder"
      ],
      "metadata": {
        "id": "PA6qPHI01MzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n",
        "                 dropout_rate = 0.1, layernorm_eps = 1e-6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.mha1 = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads = num_heads,\n",
        "            key_dim = embedding_dim,\n",
        "            dropout = dropout_rate\n",
        "        )\n",
        "\n",
        "        self.mha2 = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads = num_heads,\n",
        "            key_dim = embedding_dim,\n",
        "            dropout = dropout_rate\n",
        "        )\n",
        "\n",
        "        self.ffn = FullyConnected(\n",
        "            embedding_dim,\n",
        "            fully_connected_dim\n",
        "        )\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(\n",
        "            epsilon = layernorm_eps\n",
        "        )\n",
        "\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(\n",
        "            epsilon = layernorm_eps\n",
        "        )\n",
        "\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(\n",
        "            epsilon = layernorm_eps\n",
        "        )\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(\n",
        "            rate = dropout_rate\n",
        "        )\n",
        "\n",
        "    def call(self, x, encoder_output, is_training,\n",
        "             look_ahead_mask, padding_mask):\n",
        "\n",
        "        # masked multi head attention layer\n",
        "        multi_attn_out_1, masked_attention_weights = self.mha1(\n",
        "            query = x,\n",
        "            key = x,\n",
        "            value = x,\n",
        "            attention_mask = look_ahead_mask,\n",
        "            return_attention_scores = True\n",
        "        )\n",
        "\n",
        "        # first residual connection and layer norm\n",
        "        norm_layer_out_1 = self.layernorm1(multi_attn_out_1 + x)\n",
        "\n",
        "        # multi head attention layer\n",
        "        multi_attn_out_2, attention_weights = self.mha2(\n",
        "            query = norm_layer_out_1,\n",
        "            key = encoder_output,\n",
        "            value = encoder_output,\n",
        "            attention_mask = padding_mask,\n",
        "            return_attention_scores=True\n",
        "        )\n",
        "\n",
        "        # second residual connection and layer norm\n",
        "        norm_layer_out_2 = self.layernorm2(multi_attn_out_2 + norm_layer_out_1)\n",
        "\n",
        "        # feed forward nn\n",
        "        ffn_output = self.ffn(norm_layer_out_2)\n",
        "\n",
        "        # dropout layer\n",
        "        ffn_output = self.dropout(ffn_output, training = is_training)\n",
        "\n",
        "        output = self.layernorm3(ffn_output + norm_layer_out_2)\n",
        "\n",
        "        return output, masked_attention_weights, attention_weights"
      ],
      "metadata": {
        "id": "8c3SKvbuyXpn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = tf.random.uniform((1,3,5))\n",
        "\n",
        "dec = DecoderLayer(num_heads = 1,\n",
        "                 embedding_dim = 5,\n",
        "                 fully_connected_dim = 120)\n",
        "\n",
        "dec_out, masked_attn_weights, attn_weights = dec(q,\n",
        "                                                 encoder_output = encoder_out,\n",
        "                                                 is_training = True,\n",
        "                                                 look_ahead_mask = None,\n",
        "                                                 padding_mask = None)\n",
        "\n",
        "print(f\"q has shape:{q.shape}\")\n",
        "print(f\"Output of encoder has shape:{encoder_out.shape}\\n\")\n",
        "print(f\"Output of decoder layer has shape:{dec_out.shape}\")\n",
        "print(f\"masked attetion Weights has shape:{masked_attn_weights.shape}\")\n",
        "print(f\"attetion Weights has shape:{attn_weights.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol_c2BKIBH9k",
        "outputId": "4c944427-f6b7-4fd9-d221-f6a337043d02"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "q has shape:(1, 3, 5)\n",
            "Output of encoder has shape:(1, 2, 10)\n",
            "\n",
            "Output of decoder layer has shape:(1, 3, 5)\n",
            "masked attetion Weights has shape:(1, 1, 3, 3)\n",
            "attetion Weights has shape:(1, 1, 3, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "\n",
        "    \"full decoder\"\n",
        "\n",
        "    def __init__(self,num_layers,embedding_dim,num_heads,\n",
        "                      fully_connected_dim,target_vocab_size,\n",
        "                      maximum_position_encoding,\n",
        "                      dropout_rate=0.1, layernorm_eps=1e-6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(\n",
        "            input_dim = target_vocab_size,\n",
        "            output_dim = self.embedding_dim\n",
        "        )\n",
        "\n",
        "        self.pos_encoding = positional_encoding(\n",
        "            positions = maximum_position_encoding,\n",
        "            d_model = self.embedding_dim\n",
        "        )\n",
        "\n",
        "        # repreating decoder layer for certain num of layers\n",
        "        self.decoder_layers = [\n",
        "            DecoderLayer(\n",
        "                self.embedding_dim,\n",
        "                num_heads, fully_connected_dim,\n",
        "                dropout_rate=0.1, layernorm_eps=1e-06)\n",
        "\n",
        "            for _ in range(self.num_layers)\n",
        "            ]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, encoder_output, is_training, look_ahead_mask, padding_mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        all_attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # this scaling process helps maintain a good balance between\n",
        "        # the learned embeddings and the fixed positional encodings\n",
        "        # because the embedding is a slightly smaller than the positional encoding values\n",
        "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
        "\n",
        "        # add positional encoding\n",
        "        x += self.pos_encoding[:,:seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training = is_training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, masked_attention_weights, attention_weights = self.decoder_layers[i](\n",
        "                x, encoder_output, is_training = is_training,\n",
        "                look_ahead_mask = look_ahead_mask,\n",
        "                padding_mask = padding_mask\n",
        "            )\n",
        "\n",
        "        all_attention_weights['decoder_layer{}_block1_self_att'.format(i+1)] = masked_attention_weights\n",
        "        all_attention_weights['decoder_layer{}_block2_decenc_att'.format(i+1)] = attention_weights\n",
        "\n",
        "        return x, all_attention_weights"
      ],
      "metadata": {
        "id": "y32-bvpLrO_z"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function!\n",
        "n_layers = 5\n",
        "emb_d = 13\n",
        "n_heads = 17\n",
        "fully_connected_dim = 16\n",
        "target_vocab_size = 300\n",
        "maximum_position_encoding = 6\n",
        "\n",
        "x = np.array([[3, 2, 1, 1], [2, 1, 1, 0], [2, 1, 1, 0]])\n",
        "\n",
        "encoder_test_output = tf.convert_to_tensor(np.random.rand(3, 7, 9))\n",
        "\n",
        "look_ahead_mask = create_look_ahead_mask(x.shape[1])\n",
        "\n",
        "decoder_test = Decoder(\n",
        "    n_layers, emb_d, n_heads, fully_connected_dim, target_vocab_size,maximum_position_encoding)\n",
        "\n",
        "outd, att_weights = decoder_test(\n",
        "    x, encoder_test_output, is_training = False, look_ahead_mask = look_ahead_mask, padding_mask = None)\n",
        "\n",
        "print(f\"Using num_layers={n_layers}, embedding_dim={emb_d} and num_heads={n_heads}:\\n\")\n",
        "print(f\"x has shape:{x.shape}\")\n",
        "print(f\"Output of encoder has shape:{encoder_test_output.shape}\\n\")\n",
        "\n",
        "print(f\"Output of decoder has shape:{outd.shape}\\n\")\n",
        "\n",
        "print(\"Attention weights:\")\n",
        "for name, tensor in att_weights.items():\n",
        "    print(f\"{name} has shape:{tensor.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5N5cg2augyR",
        "outputId": "a1651d75-94ab-4c6a-c7cb-94c27ae7f5c6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using num_layers=5, embedding_dim=13 and num_heads=17:\n",
            "\n",
            "x has shape:(3, 4)\n",
            "Output of encoder has shape:(3, 7, 9)\n",
            "\n",
            "Output of decoder has shape:(3, 4, 13)\n",
            "\n",
            "Attention weights:\n",
            "decoder_layer5_block1_self_att has shape:(3, 17, 4, 4)\n",
            "decoder_layer5_block2_decenc_att has shape:(3, 17, 4, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer"
      ],
      "metadata": {
        "id": "sPom3AHZwmFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_layers,\n",
        "                 input_vocab_size,\n",
        "                 target_vocab_size,\n",
        "                 embedding_dim,\n",
        "                 maximum_position_encoding_input,\n",
        "                 maximum_position_encoding_target,\n",
        "                 num_heads,\n",
        "                 fully_connected_dim,\n",
        "                 dropout_rate=0.1,\n",
        "                 layernorm_eps=1e-06):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers = num_layers,\n",
        "                               vocab_size = input_vocab_size,\n",
        "                               embedding_dim = embedding_dim,\n",
        "                               maximum_position_encoding = maximum_position_encoding_input,\n",
        "                               num_heads = num_heads,\n",
        "                               fully_connected_dim = fully_connected_dim,\n",
        "                               dropout_rate = dropout_rate,\n",
        "                               layernorm_eps = layernorm_eps\n",
        "        )\n",
        "\n",
        "        self.decoder = Decoder(num_layers = num_layers,\n",
        "                               embedding_dim = embedding_dim,\n",
        "                               num_heads = num_heads,\n",
        "                               fully_connected_dim = fully_connected_dim,\n",
        "                               target_vocab_size = target_vocab_size,\n",
        "                               maximum_position_encoding = maximum_position_encoding_target,\n",
        "                               dropout_rate = dropout_rate,\n",
        "                               layernorm_eps = layernorm_eps\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        self.fc = tf.keras.layers.Dense(\n",
        "            target_vocab_size,\n",
        "            activation = \"softmax\"\n",
        "        )\n",
        "\n",
        "\n",
        "    def call(self,input, target, is_training,\n",
        "             enc_padding_mask, dec_padding_mask,\n",
        "             look_ahead_mask):\n",
        "\n",
        "        enc_out = self.encoder(input,\n",
        "                               is_training = is_training,\n",
        "                               mask = enc_padding_mask\n",
        "        )\n",
        "\n",
        "        dec_out, _ = self.decoder(target,\n",
        "                                  enc_out,\n",
        "                                  is_training = is_training,\n",
        "                                  look_ahead_mask = look_ahead_mask,\n",
        "                                  padding_mask = dec_padding_mask\n",
        "        )\n",
        "\n",
        "        output = self.fc(dec_out)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "r9c1lmK3jnvo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = tf.constant([[2, 3, 1, 3, 0, 0, 0]])\n",
        "tar = tf.constant([[1, 3, 4, 0, 0, 0, 0]])\n",
        "\n",
        "trans = Transformer(\n",
        "    num_layers=1,\n",
        "    input_vocab_size=5,\n",
        "    target_vocab_size=6,\n",
        "    embedding_dim=10,\n",
        "    maximum_position_encoding_input=10,\n",
        "    maximum_position_encoding_target = 10,\n",
        "    num_heads=10,\n",
        "    fully_connected_dim=13\n",
        "    )\n",
        "\n",
        "enc_padding_mask = create_padding_mask(inp)\n",
        "dec_padding_mask = create_padding_mask(tar)\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[1])\n",
        "\n",
        "trans(inp, tar, is_training = False,\n",
        "      enc_padding_mask = enc_padding_mask,\n",
        "      dec_padding_mask = dec_padding_mask,\n",
        "      look_ahead_mask = look_ahead_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6VJr9632-ys",
        "outputId": "bbcd227c-f787-48cc-bb6d-1da205aa1bdc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'encoder_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 7, 6), dtype=float32, numpy=\n",
              "array([[[0.01487851, 0.20799032, 0.16125268, 0.33717978, 0.07287869,\n",
              "         0.20582001],\n",
              "        [0.03978156, 0.20249669, 0.25221854, 0.2504698 , 0.04786408,\n",
              "         0.20716928],\n",
              "        [0.06639344, 0.22112691, 0.19102435, 0.27094004, 0.03723403,\n",
              "         0.21328126],\n",
              "        [0.07335594, 0.25044033, 0.11506843, 0.30594125, 0.04390745,\n",
              "         0.21128659],\n",
              "        [0.06299673, 0.23691863, 0.06678327, 0.35449   , 0.06316341,\n",
              "         0.21564794],\n",
              "        [0.04523607, 0.21091118, 0.04452794, 0.3888606 , 0.0956915 ,\n",
              "         0.21477267],\n",
              "        [0.05040847, 0.23726067, 0.06002739, 0.32277077, 0.11378585,\n",
              "         0.21574683]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialize the Model\n"
      ],
      "metadata": {
        "id": "XZc-xsO7PITJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 2\n",
        "embedding_dim = 128\n",
        "fully_connected_dim = 128\n",
        "num_heads = 2\n",
        "positional_encoding_length = 256\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "transformer = Transformer(\n",
        "    num_layers = num_layers,\n",
        "    input_vocab_size = vocab_size,\n",
        "    target_vocab_size = vocab_size,\n",
        "    embedding_dim = embedding_dim,\n",
        "    maximum_position_encoding_input = positional_encoding_length,\n",
        "    maximum_position_encoding_target = positional_encoding_length,\n",
        "    num_heads = num_heads,\n",
        "    fully_connected_dim = fully_connected_dim\n",
        ")"
      ],
      "metadata": {
        "id": "dalbPJChAbRi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare for Training the Model"
      ],
      "metadata": {
        "id": "dBPU7zama70k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "    def __init__(self, d_model, warmup_steps = 4000):\n",
        "\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = tf.cast(d_model, dtype=tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "\n",
        "        step = tf.cast(step, dtype=tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "learning_rate = CustomSchedule(embedding_dim)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "id": "YmPodIUBQ1Mf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps=500000\n",
        "\n",
        "plt.plot(learning_rate(range(steps)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "sTvJ8oUcmVGj",
        "outputId": "d0d44c3f-ceab-48a9-dc13-5dac1021ab6b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c1c5ec08450>]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(true, pred):\n",
        "\n",
        "    loss_func = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits = False, # softmax used\n",
        "        reduction = 'none'\n",
        "    )\n",
        "\n",
        "    # mask to ignore padding in y_true\n",
        "    mask = tf.cast(tf.logical_not(tf.equal(true, 0)), loss_func.dtype)\n",
        "\n",
        "    loss = loss_func(true, pred)\n",
        "\n",
        "    # apply mask\n",
        "    loss *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss, axis = -1) / tf.reduce_sum(mask , axis=-1)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
        "\n",
        "losses = []"
      ],
      "metadata": {
        "id": "yv6-zIodqIBh"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(model, input, target):\n",
        "\n",
        "    \"\"\"custom training function alternative to using model.compile() and model.fit(),\n",
        "        but with added extra flexibility.\"\"\"\n",
        "\n",
        "    # prepair target\n",
        "    tar_inp = target[:, :-1] # input target wothout EOS\n",
        "    tar_real = target[:, 1:] # actual target without SOS\n",
        "\n",
        "    # maskes\n",
        "    enc_padding_mask = create_padding_mask(input)\n",
        "    dec_padding_mask = create_padding_mask(input)\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar_inp)[1]) # target seq_len\n",
        "\n",
        "    # TensorFlow starts recording all operations that involve tensors\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        # Forward Pass\n",
        "        predictions = model(\n",
        "            input,\n",
        "            tar_inp,\n",
        "            is_training=True,\n",
        "            enc_padding_mask = enc_padding_mask,\n",
        "            dec_padding_mask = dec_padding_mask,\n",
        "            look_ahead_mask = look_ahead_mask\n",
        "        )\n",
        "\n",
        "        # loss\n",
        "        loss = masked_loss(tar_real, predictions)\n",
        "\n",
        "    # After the block ends, use tape.gradient() to automatically compute gradients\n",
        "    gradient = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
        "\n",
        "    # update loss\n",
        "    train_loss(loss)"
      ],
      "metadata": {
        "id": "QOV_PDW0Vdjg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_step(transformer, list(dataset.take(1))[0][0], list(dataset.take(1))[0][1])"
      ],
      "metadata": {
        "id": "OJNbbjJ3JMpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55601f5-e432-4d18-fbe3-3ff9c2f27e8f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'encoder_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summarization\n"
      ],
      "metadata": {
        "id": "xlA55_edSTCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def next_word(model, encoder_input, output):\n",
        "\n",
        "    \"A function for predicting the next word in the summary\"\n",
        "\n",
        "    # used in encoder multi head attention layer\n",
        "    enc_padding_mask = create_padding_mask(encoder_input)\n",
        "\n",
        "    # used in decoder masked multi head attention layer\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(output)[1])\n",
        "\n",
        "    # used in decoder multi head attention layer\n",
        "    # we need to pad the encoder positions that comes from the encoder\n",
        "    dec_padding_mask = create_padding_mask(encoder_input)\n",
        "\n",
        "    predictions = model(\n",
        "        encoder_input,\n",
        "        output,\n",
        "        is_training = False,\n",
        "        enc_padding_mask = enc_padding_mask,\n",
        "        dec_padding_mask = dec_padding_mask,\n",
        "        look_ahead_mask = look_ahead_mask)\n",
        "\n",
        "    # select the hidden state for the last token\n",
        "    predictions = predictions[:, -1:, :]\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions ,axis = -1), tf.int32)\n",
        "\n",
        "    return predicted_id"
      ],
      "metadata": {
        "id": "bpNWLrBGoxgg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_document = tokenizer.texts_to_sequences([\"see you\"])\n",
        "input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "encoder_input = tf.expand_dims(input_document[0], 0)\n",
        "\n",
        "output = tf.expand_dims([tokenizer.word_index[\"[SOS]\"]], 0)\n",
        "\n",
        "predicted_token = next_word(transformer, encoder_input, output)\n",
        "print(f\"Predicted token: {predicted_token}\")\n",
        "\n",
        "predicted_word = tokenizer.sequences_to_texts(predicted_token.numpy())[0]\n",
        "print(f\"Predicted word: {predicted_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfxGgnQxSZ7a",
        "outputId": "cafeeae7-e202-47a4-fe77-15810eb52507"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted token: [[30039]]\n",
            "Predicted word: puh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(model, input_document, decoder_maxlen):\n",
        "\n",
        "    \"A function for summarization using the transformer model\"\n",
        "\n",
        "    input_document = tokenizer.texts_to_sequences([input_document])\n",
        "\n",
        "    input_document = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        input_document,\n",
        "        maxlen = encoder_maxlen,\n",
        "        padding = 'post',\n",
        "        truncating = 'post'\n",
        "    )\n",
        "\n",
        "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
        "\n",
        "    output = tf.expand_dims([tokenizer.word_index[\"[SOS]\"]], 0)\n",
        "\n",
        "    for i in range(decoder_maxlen):\n",
        "\n",
        "        predicted_id = next_word(model, encoder_input, output)\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "        if predicted_id == tokenizer.word_index[\"[EOS]\"]:\n",
        "            break\n",
        "\n",
        "    return tokenizer.sequences_to_texts(output.numpy())[0]"
      ],
      "metadata": {
        "id": "ry8mm4n8Wf5X"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set_example = 0\n",
        "\n",
        "# Check a summary of a document from the training set\n",
        "print('Training set example:')\n",
        "print(document[training_set_example])\n",
        "print('\\nHuman written summary:')\n",
        "print(summary[training_set_example])\n",
        "print('\\nModel written summary:')\n",
        "summarize(transformer, document[training_set_example], decoder_maxlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "IvAKlXt4Wfxr",
        "outputId": "24828f66-e4c7-4f3b-b85a-fc318ed12088"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set example:\n",
            "[SOS] amanda: i baked cookies. do you want some? jerry: sure! amanda: i'll bring you tomorrow :-) [EOS]\n",
            "\n",
            "Human written summary:\n",
            "[SOS] amanda baked cookies and will bring jerry some tomorrow. [EOS]\n",
            "\n",
            "Model written summary:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[SOS] puh promptly terminates gr8 frittur ozan laaaast stapler loooong birthady flavoured towns shocks cleaners leonard's primal birthady ozan valentines maintains pigment morality decade decade kawasaki case floor extra determination determination determination cartman moldova kendrick robinson ddi chris'es robinson isnt sloooow counseling determination waits waits aaaa assesment wirelessly valentines dilan convesation\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the model"
      ],
      "metadata": {
        "id": "qfLHNP6Y0d9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "number_of_batches = len(list(dataset))\n",
        "\n",
        "test_example = 0\n",
        "true_summary = summary_test[test_example]\n",
        "true_document = document_test[test_example]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    start = time.time()\n",
        "    train_loss.reset_state()\n",
        "\n",
        "    for batch, (inp, tar) in enumerate(dataset):\n",
        "\n",
        "        train_step(transformer, inp, tar)\n",
        "\n",
        "    print (f'Epoch {epoch + 1}, Loss {train_loss.result():.4f}')\n",
        "\n",
        "    losses.append(train_loss.result())\n",
        "\n",
        "    print (f'Time taken for one epoch: {time.time() - start} sec')\n",
        "    print('Example summarization on the test set:')\n",
        "    print('  True summarization:')\n",
        "    print(f'    {true_summary}')\n",
        "    print('  Predicted summarization:')\n",
        "    print(f'    {summarize(transformer, true_document, decoder_maxlen)}\\n')"
      ],
      "metadata": {
        "id": "zQ5J5nkkYXS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "4475f4eb-3b24-4746-f382-035fba2b17a4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss 9.9255\n",
            "Time taken for one epoch: 29.802659511566162 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] [EOS]\n",
            "\n",
            "Epoch 2, Loss 7.7231\n",
            "Time taken for one epoch: 25.22883677482605 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] [EOS]\n",
            "\n",
            "Epoch 3, Loss 6.6201\n",
            "Time taken for one epoch: 25.495482921600342 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] is going to the [EOS]\n",
            "\n",
            "Epoch 4, Loss 5.9580\n",
            "Time taken for one epoch: 25.955681324005127 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] the new new new new new new new new new new new new new new new new new new new new new new new new new new new new new [EOS]\n",
            "\n",
            "Epoch 5, Loss 5.4948\n",
            "Time taken for one epoch: 25.800309896469116 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] john is going to go to the party [EOS]\n",
            "\n",
            "Epoch 6, Loss 5.1916\n",
            "Time taken for one epoch: 26.19454836845398 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] mary is going to buy a new job [EOS]\n",
            "\n",
            "Epoch 7, Loss 4.9263\n",
            "Time taken for one epoch: 26.953242540359497 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] jane is going to buy a lot of her [EOS]\n",
            "\n",
            "Epoch 8, Loss 4.6419\n",
            "Time taken for one epoch: 27.019519567489624 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] jane is going to get her phone with her mother [EOS]\n",
            "\n",
            "Epoch 9, Loss 4.3413\n",
            "Time taken for one epoch: 26.7216157913208 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] hannah has to get the number of the number of the number of the phone [EOS]\n",
            "\n",
            "Epoch 10, Loss 4.0304\n",
            "Time taken for one epoch: 26.987008333206177 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] hannah and hannah are going to the number of the number [EOS]\n",
            "\n",
            "Epoch 11, Loss 3.7221\n",
            "Time taken for one epoch: 26.997509479522705 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] hannah is going to get back to the office today [EOS]\n",
            "\n",
            "Epoch 12, Loss 3.4239\n",
            "Time taken for one epoch: 26.930566549301147 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] amanda is going to visit amanda and hannah [EOS]\n",
            "\n",
            "Epoch 13, Loss 3.1338\n",
            "Time taken for one epoch: 27.130642890930176 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] amanda is going to get some chat with hannah and hannah [EOS]\n",
            "\n",
            "Epoch 14, Loss 2.8631\n",
            "Time taken for one epoch: 26.994104623794556 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] hannah will check if she has a lot of town [EOS]\n",
            "\n",
            "Epoch 15, Loss 2.6087\n",
            "Time taken for one epoch: 26.91323208808899 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] amanda is going to visit amanda and amanda [EOS]\n",
            "\n",
            "Epoch 16, Loss 2.3732\n",
            "Time taken for one epoch: 26.91319990158081 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] hannah will go to town for emma and amanda [EOS]\n",
            "\n",
            "Epoch 17, Loss 2.1618\n",
            "Time taken for one epoch: 26.95672583580017 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] hannah will check if she has a trip [EOS]\n",
            "\n",
            "Epoch 18, Loss 1.9680\n",
            "Time taken for one epoch: 27.394206047058105 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] hannah can't find out of town she is going to check out with her [EOS]\n",
            "\n",
            "Epoch 19, Loss 1.7584\n",
            "Time taken for one epoch: 27.14171314239502 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] amanda can't find her number she is seeing someone for amanda and amanda [EOS]\n",
            "\n",
            "Epoch 20, Loss 1.5722\n",
            "Time taken for one epoch: 27.038809537887573 sec\n",
            "Example summarization on the test set:\n",
            "  True summarization:\n",
            "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
            "  Predicted summarization:\n",
            "    [SOS] hannah called molly at charles' home [EOS]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "NUcTjfNUmUkL",
        "outputId": "fd8f1ac6-9e46-46fd-d30b-e8d432034b5d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"model.weights.h5\""
      ],
      "metadata": {
        "id": "QzaZXUKmJuey"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformer.save_weights(save_dir)"
      ],
      "metadata": {
        "id": "4BP5rlqK8ZlW"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformer.load_weights(save_dir)"
      ],
      "metadata": {
        "id": "hJkVNHQhKBT1",
        "collapsed": true
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required package if not already installed\n",
        "!pip install rouge-score\n",
        "\n",
        "from rouge_score import rouge_scorer\n",
        "import numpy as np\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# Calculate metrics for all test samples\n",
        "rouge1_scores = []\n",
        "rouge2_scores = []\n",
        "rougeL_scores = []\n",
        "\n",
        "print(\"Evaluating all test samples...\")\n",
        "\n",
        "for idx in range(len(document_test)):\n",
        "    # Generate prediction\n",
        "    predicted_summary = summarize(transformer, document_test[idx], decoder_maxlen)\n",
        "\n",
        "    # Calculate ROUGE scores\n",
        "    scores = scorer.score(summary_test[idx], predicted_summary)\n",
        "    rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "    rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "    rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "# Print overall metrics\n",
        "print(\"\\n=== Model Evaluation Results ===\")\n",
        "print(f\"ROUGE-1 Score: {np.mean(rouge1_scores):.4f}\")\n",
        "print(f\"ROUGE-2 Score: {np.mean(rouge2_scores):.4f}\")\n",
        "print(f\"ROUGE-L Score: {np.mean(rougeL_scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYtdKhkTDgjD",
        "outputId": "2ea63f11-83da-4682-a9c7-c16f447e5f71",
        "collapsed": true
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Model Evaluation Results ===\n",
            "ROUGE-1 Score: 0.3629\n",
            "ROUGE-2 Score: 0.0899\n",
            "ROUGE-L Score: 0.3092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set_example = 41\n",
        "\n",
        "# Check a summary of a document from the training set\n",
        "print('Test set example:')\n",
        "print(document_test[training_set_example])\n",
        "print('\\nHuman written summary:')\n",
        "print(summary_test[training_set_example])\n",
        "print('\\nModel written summary:')\n",
        "print(summarize(transformer, document_test[training_set_example], decoder_maxlen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OpE6p3R3yap",
        "outputId": "6fdc6e10-eadb-4b16-dd2a-5ff2c0c494f6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set example:\n",
            "[SOS] frank: son, will you come home this weekend? son: not sure yet. something happened? frank: of course not. your mother miss you. son: i miss her too. frank: so will you com? son: i will try. frank: good, i will tell your mother that you will come son: oh, dad.. ok i will come. [EOS]\n",
            "\n",
            "Human written summary:\n",
            "[SOS] son is coming to see his parents' this weekend. [EOS]\n",
            "\n",
            "Model written summary:\n",
            "[SOS] frank will come home this weekend of a son oliver cigarettes and decided to show up [EOS]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0_xWBqgN7SDx"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}
